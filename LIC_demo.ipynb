{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4F3U9fYblVO"
   },
   "source": [
    "1. 신경망 기반 이미지 압축 모델들을 제공하는 라이브러리 CompressAI를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cpADeqVkYKo-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting compressai==1.2.8\n",
      "  Downloading compressai-1.2.8.tar.gz (183 kB)\n",
      "     ------------------------------------- 183.8/183.8 kB 10.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting einops\n",
      "  Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "Collecting numpy<2.0,>=1.21.0\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "     --------------------------------------- 15.8/15.8 MB 50.3 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "Collecting pybind11>=2.6.0\n",
      "  Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
      "Collecting pytorch-msssim\n",
      "  Using cached pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.3-cp311-cp311-win_amd64.whl (38.7 MB)\n",
      "Collecting setuptools>=68\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting tomli>=2.2.1\n",
      "  Downloading tomli-2.3.0-cp311-cp311-win_amd64.whl (107 kB)\n",
      "     -------------------------------------- 107.2/107.2 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting torch-geometric>=2.3.0\n",
      "  Using cached torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
      "Collecting torch>=1.13.1\n",
      "  Using cached torch-2.9.0-cp311-cp311-win_amd64.whl (109.3 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.0-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\pyr82\\appdata\\roaming\\python\\python311\\site-packages (from compressai==1.2.8) (4.15.0)\n",
      "Collecting wheel>=0.32.0\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Collecting sympy>=1.13.3\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting networkx>=2.5.1\n",
      "  Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting fsspec>=0.8.5\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.13.2-cp311-cp311-win_amd64.whl (456 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\pyr82\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric>=2.3.0->compressai==1.2.8) (7.1.1)\n",
      "Collecting pyparsing\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from torch-geometric>=2.3.0->compressai==1.2.8) (2.31.0)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.60.1-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-win_amd64.whl (73 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pyr82\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->compressai==1.2.8) (25.0)\n",
      "Collecting pillow>=8\n",
      "  Using cached pillow-12.0.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pyr82\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->compressai==1.2.8) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pyr82\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->compressai==1.2.8) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pyr82\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->compressai==1.2.8) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting aiosignal>=1.4.0\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.8.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.7.0-cp311-cp311-win_amd64.whl (46 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Using cached propcache-0.4.1-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Using cached yarl-1.22.0-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached markupsafe-3.0.3-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.8) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.8) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.8) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.8) (2023.7.22)\n",
      "Building wheels for collected packages: compressai\n",
      "  Building wheel for compressai (pyproject.toml): started\n",
      "  Building wheel for compressai (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for compressai: filename=compressai-1.2.8-cp311-cp311-win_amd64.whl size=425163 sha256=305b7502e894405a2409ebeee33100aee1753d76087caa064cc6e7136ab83667\n",
      "  Stored in directory: c:\\users\\pyr82\\appdata\\local\\pip\\cache\\wheels\\80\\62\\ae\\9b089b3bc2902d70ec61d229722954862e7b666767e0e506f2\n",
      "Successfully built compressai\n",
      "Installing collected packages: pytz, mpmath, xxhash, wheel, tzdata, tqdm, tomli, sympy, setuptools, pyparsing, pybind11, propcache, pillow, numpy, networkx, multidict, MarkupSafe, kiwisolver, fsspec, frozenlist, fonttools, filelock, einops, cycler, attrs, aiohappyeyeballs, yarl, scipy, pandas, jinja2, contourpy, aiosignal, torch, matplotlib, aiohttp, torchvision, torch-geometric, pytorch-msssim, compressai\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] 지정된 파일을 찾을 수 없습니다: 'c:\\\\Python311\\\\Scripts\\\\wheel.exe' -> 'c:\\\\Python311\\\\Scripts\\\\wheel.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install compressai==1.2.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBcga2bykVbl"
   },
   "source": [
    "2. CompressAI 라이브러리로부터 코덱 호출 (가중치 다운로드 시 시간 소요될 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZxEY8EEjtTX"
   },
   "outputs": [],
   "source": [
    "from compressai.zoo import image_models\n",
    "\n",
    "QP = 1 # [1, ..., 8] 미팅 때 논의했던 quality point, 높을 수록 화질 향상, 비트량 증가\n",
    "\n",
    "codec_config = image_models['mbt2018-mean']    # CompressAI가 제공하는 코덱 모델 중 mbt2018-mean 선택\n",
    "\n",
    "codec = codec_config(quality=QP, metric=\"mse\", pretrained=True, progress=True) # 원하는 QP에 대해 학습된 모델 로딩\n",
    "codec = codec.eval()    # 평가 모드로 전환\n",
    "codec.update()          # 코덱 초기화 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvP1Duc0liqe"
   },
   "source": [
    "3. 예시 이미지 로딩을 위한 유틸 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFL-c1KIln89"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "def plot_img(torch_img):\n",
    "    if len(torch_img.shape) == 4:\n",
    "        torch_img = make_grid(torch_img)\n",
    "    plt.imshow(torch_img.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def PSNR(input1, input2):\n",
    "    mse = torch.mean((input1 - input2) ** 2)\n",
    "    psnr = 20 * torch.log10(1 / torch.sqrt(mse))\n",
    "    return psnr.item()\n",
    "\n",
    "def save_torch_image(img, save_path):\n",
    "    img = img.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
    "    img = np.clip(np.rint(img * 255), 0, 255).astype(np.uint8)\n",
    "    Image.fromarray(img).save(save_path)\n",
    "\n",
    "def load_torch_image(path):\n",
    "    input_image = Image.open(path).convert('RGB')\n",
    "    input_image = np.asarray(input_image).astype('float64').transpose(2, 0, 1)\n",
    "    input_image = torch.from_numpy(input_image).type(torch.FloatTensor)\n",
    "    input_image = input_image.unsqueeze(0)/255\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vv699-Zjnpf3"
   },
   "source": [
    "4. 예시 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5GQ0OpYl69v"
   },
   "outputs": [],
   "source": [
    "img = load_torch_image('./kodim01.png')\n",
    "print(img.shape)\n",
    "plot_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qc5PH67CnwEN"
   },
   "source": [
    "5. 이미지 압축 및 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtKONZ0Jnx9m"
   },
   "outputs": [],
   "source": [
    "# CompressAI의 이미지 압축 모델들은 가로 세로가 64의 배수일 때 정상 동작합니다.\n",
    "# 압축 전후로 패딩 및 크롭이 필요합니다. (64의 배수로 만들어주기 위해)\n",
    "\n",
    "def get_padded_img(img, p=64):\n",
    "    height, width = img.shape[-2:]\n",
    "    new_h = (height + p - 1) // p * p\n",
    "    new_w = (width + p - 1) // p * p\n",
    "    padding_l = 0\n",
    "    padding_r = new_w - width - padding_l\n",
    "    padding_t = 0\n",
    "    padding_b = new_h - height - padding_t\n",
    "    pad_info = (padding_l, padding_r, padding_t, padding_b)\n",
    "    x_padded = torch.nn.functional.pad(\n",
    "        img,\n",
    "        pad_info,\n",
    "        mode=\"constant\", value=0,\n",
    "    )\n",
    "    return x_padded, pad_info\n",
    "\n",
    "def get_cropped_img(padded_img, pad_info):\n",
    "    reverse_pad_info = tuple(-p for p in pad_info)\n",
    "    cropped_img = torch.nn.functional.pad(padded_img, reverse_pad_info)\n",
    "    return cropped_img\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Padding (+ get padding information)\n",
    "    img_padded, pad_info = get_padded_img(img)\n",
    "\n",
    "    # Encoding (압축, img -> strings)\n",
    "    compressed = codec.compress(img_padded)\n",
    "    strings = compressed['strings']\n",
    "    shape = compressed['shape'] # 디코딩을 위해 필요한 부가 정보\n",
    "\n",
    "    # Decoding (복원, strings -> img)\n",
    "    decompressed = codec.decompress(strings=strings, shape=shape)\n",
    "    decoded_img = decompressed['x_hat']\n",
    "\n",
    "    # Cropping (using padding information)\n",
    "    cropped_decoded_img = get_cropped_img(decoded_img, pad_info)\n",
    "\n",
    "# Visualization (with Original image)\n",
    "plot_img(torch.cat([img, cropped_decoded_img], dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ibj6P9EBqcNl"
   },
   "source": [
    "6. 압축 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMuHwL4RqbSX"
   },
   "outputs": [],
   "source": [
    "psnr = PSNR(img, cropped_decoded_img)\n",
    "num_pixels = img.shape[-2] * img.shape[-1]\n",
    "bpp = sum(len(s[0]) * 8 for s in strings) / num_pixels   # bits per pixel : 데이터 양을 영상 해상도로 정규화한 값\n",
    "print(f\"PSNR: {psnr:.3f} | Bpp: {bpp:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4VvttA4r9XH"
   },
   "source": [
    "위의 내용을 공부한 후에, 압축된 영상에 대한 데이터셋을 뽑으려면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aC2nTMuqsCL9"
   },
   "outputs": [],
   "source": [
    "################# 유틸 함수 정의 ###########\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from compressai.zoo import image_models\n",
    "\n",
    "def plot_img(torch_img):\n",
    "    if len(torch_img.shape) == 4:\n",
    "        torch_img = make_grid(torch_img)\n",
    "    plt.imshow(torch_img.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def PSNR(input1, input2):\n",
    "    mse = torch.mean((input1 - input2) ** 2)\n",
    "    psnr = 20 * torch.log10(1 / torch.sqrt(mse))\n",
    "    return psnr.item()\n",
    "\n",
    "def save_torch_image(img, save_path):\n",
    "    img = img.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
    "    img = np.clip(np.rint(img * 255), 0, 255).astype(np.uint8)\n",
    "    Image.fromarray(img).save(save_path)\n",
    "\n",
    "def load_torch_image(path):\n",
    "    input_image = Image.open(path).convert('RGB')\n",
    "    input_image = np.asarray(input_image).astype('float64').transpose(2, 0, 1)\n",
    "    input_image = torch.from_numpy(input_image).type(torch.FloatTensor)\n",
    "    input_image = input_image.unsqueeze(0)/255\n",
    "    return input_image\n",
    "\n",
    "def get_padded_img(img, p=64):\n",
    "    height, width = img.shape[-2:]\n",
    "    new_h = (height + p - 1) // p * p\n",
    "    new_w = (width + p - 1) // p * p\n",
    "    padding_l = 0\n",
    "    padding_r = new_w - width - padding_l\n",
    "    padding_t = 0\n",
    "    padding_b = new_h - height - padding_t\n",
    "    pad_info = (padding_l, padding_r, padding_t, padding_b)\n",
    "    x_padded = torch.nn.functional.pad(\n",
    "        img,\n",
    "        pad_info,\n",
    "        mode=\"constant\", value=0,\n",
    "    )\n",
    "    return x_padded, pad_info\n",
    "\n",
    "def get_cropped_img(padded_img, pad_info):\n",
    "    reverse_pad_info = tuple(-p for p in pad_info)\n",
    "    cropped_img = torch.nn.functional.pad(padded_img, reverse_pad_info)\n",
    "    return cropped_img\n",
    "############################################\n",
    "\n",
    "\n",
    "################# 수정 필요 ################\n",
    "data_path = Path('./kodak24')               # path for your dataset\n",
    "save_path = Path('./kodak24_compressed')    # path for compressed dataset\n",
    "############################################\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "QP_list = [1, 2] # 테스트하고자 하는 QPs\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "for QP in QP_list:  # 테스트하고자 하는 각 QP에 대하여.\n",
    "    os.makedirs(save_path / f'qp{QP}', exist_ok=True)\n",
    "\n",
    "    codec_config = image_models['mbt2018-mean']\n",
    "    codec = codec_config(quality=QP, metric=\"mse\", pretrained=True, progress=True)\n",
    "    codec = codec.to(device)\n",
    "    codec = codec.eval()\n",
    "    codec.update()\n",
    "\n",
    "    file_paths = img_paths = sorted([\n",
    "        p for p in data_path.iterdir()\n",
    "        if p.suffix.lower() in [\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\"]\n",
    "        ])\n",
    "\n",
    "    psnrs = []\n",
    "    bpps = []\n",
    "    for img_path in file_paths:\n",
    "        img = load_torch_image(img_path).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Padding (+ get padding information)\n",
    "            img_padded, pad_info = get_padded_img(img)\n",
    "\n",
    "            # Encoding (압축, img -> strings)\n",
    "            compressed = codec.compress(img_padded)\n",
    "            strings = compressed['strings']\n",
    "            shape = compressed['shape'] # 디코딩을 위해 필요한 부가 정보\n",
    "\n",
    "            # Decoding (복원, strings -> img)\n",
    "            decompressed = codec.decompress(strings=strings, shape=shape)\n",
    "            decoded_img = decompressed['x_hat']\n",
    "\n",
    "            # Cropping (using padding information)\n",
    "            cropped_decoded_img = get_cropped_img(decoded_img, pad_info)\n",
    "            num_pixels = img.shape[-2] * img.shape[-1]\n",
    "            bpp = sum(len(s[0]) * 8 for s in strings) / num_pixels   # bits per pixel : 데이터 양을 영상 해상도로 정규화한 값\n",
    "            bpps.append(bpp)\n",
    "            psnrs.append(PSNR(img, cropped_decoded_img))\n",
    "            save_torch_image(img, save_path / f'qp{QP}' / img_path.name)\n",
    "\n",
    "    print(f\"QP: {QP} completed, averaged PSNR: {sum(psnrs) / len(file_paths):.3f} | Bpp: {sum(bpps) / len(file_paths):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOvIyND0EqMa3P58Q6LZ2Zg",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
